{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import dask.dataframe as dd\n",
    "import dateparser\n",
    "import swifter\n",
    "from fastparquet import ParquetFile\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import datetime\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw APC and append\n",
    "\n",
    "The raw APC data files for 2019-2020 are saved in Teams under general > datasets > wego-occupancy > APCData > Raw APC 2019-2020 data. Change the classpaths when reading in files throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read raw data files as string. \n",
    "jan_mar = pd.read_csv('rawdata/Jan-Mar2019.txt', dtype = str)\n",
    "apr_jun = pd.read_csv('rawdata/apr-jun 2019.txt', dtype = str)\n",
    "jul_sept = pd.read_csv('rawdata/jul-sept 2019.txt', dtype = str)\n",
    "oct_dec = pd.read_csv('rawdata/oct-dec 2019.txt', dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append data\n",
    "apc_df = jan_mar.append(apr_jun)\n",
    "apc_df = apc_df.append(jul_sept)\n",
    "apc_df = apc_df.append(oct_dec)\n",
    "apc_df = apc_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns and filter for ride_check_mode = 2\n",
    "apc_df.columns = ['initial_load', 'apc_stop_id', 'stop_number', 'e_time', 'actual_arrival_time', 'actual_depart_time',\n",
    "                 'scheduled_arrival_time', 'scheduled_departure_time', 'sequence', 'board_count', 'alight_count',\n",
    "                 'ride_check_type', 'line', 'block_name', 'bus_number', 'service_id', 'ride_check_date', 'pattern',\n",
    "                 'pattern_id', 'apc_trip_id', 'apc_lat', 'apc_lon', 'stop_abbr', 'apc_stop_name', 'ride_check_mode']\n",
    "apc_df = apc_df.loc[apc_df['ride_check_mode'] == '2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3205142"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apc_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean APC data\n",
    "step 1: cast strings to appropriate types\n",
    "step 2: delete ride check type column\n",
    "step 3: convert dates to datetime\n",
    "step 4: convert times from seconds past midnight to HH/MM/SS\n",
    "**for 2019 only: remove data from dates 10/17/19 and 10/18/19 (these represent faulty records in the data)\n",
    "\n",
    "These processing steps have been run on the raw 2019 and 2020 APC data and both files are saved in Teams under general > datasets > wego-occupancy > APCData > Cleaned APC 2019-2020 data. The 2020 cleaned data file is called apc_cleaned_jan_through_oct15_2020parquet.gz and the 2019 cleaned data file is called apc_cleaned_jan_through_dec_2019parquet.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert initial load, ride check mode, sequence, line abbr to int 18\n",
    "apc_df['initial_load'] = apc_df['initial_load'].astype('int8')\n",
    "apc_df['ride_check_mode'] = apc_df['ride_check_mode'].astype('int8')\n",
    "apc_df['sequence'] = apc_df['sequence'].astype('int8')\n",
    "apc_df['line'] = apc_df['line'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert stop id, stop number to int 16\n",
    "apc_df['apc_stop_id']=apc_df['apc_stop_id'].astype('int16')\n",
    "apc_df['stop_number']=apc_df['stop_number'].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert board count, alight count to int\n",
    "apc_df['board_count']=apc_df['board_count'].astype('int64')\n",
    "apc_df['alight_count']=apc_df['alight_count'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert  apc_trip_id, lat, long, pattern id, bus number, service id to int \n",
    "apc_df['apc_trip_id']=apc_df['apc_trip_id'].astype(int)\n",
    "apc_df['apc_lat']=apc_df['apc_lat'].astype(int)\n",
    "apc_df['apc_lon']=apc_df['apc_lon'].astype(int)\n",
    "apc_df['pattern_id']=apc_df['pattern_id'].astype(int)\n",
    "apc_df['bus_number']=apc_df['bus_number'].astype(int)\n",
    "apc_df['service_id']=apc_df['service_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert stop abbr, stop name, block name to string\n",
    "apc_df['stop_abbr'] = apc_df['stop_abbr'].astype(str)\n",
    "apc_df['apc_stop_name'] = apc_df['apc_stop_name'].astype(str)\n",
    "apc_df['block_name'] = apc_df['block_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete ride_check_type column\n",
    "apc_df = apc_df.drop('ride_check_type', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR 2019 ONLY: drop dates 10/17/19 and 10/18/19\n",
    "apc_df = apc_df[(apc_df.ride_check_date != '20191017') & (apc_df.ride_check_date != '20191018')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_load</th>\n",
       "      <th>apc_stop_id</th>\n",
       "      <th>stop_number</th>\n",
       "      <th>e_time</th>\n",
       "      <th>actual_arrival_time</th>\n",
       "      <th>actual_depart_time</th>\n",
       "      <th>scheduled_arrival_time</th>\n",
       "      <th>scheduled_departure_time</th>\n",
       "      <th>sequence</th>\n",
       "      <th>board_count</th>\n",
       "      <th>alight_count</th>\n",
       "      <th>line</th>\n",
       "      <th>block_name</th>\n",
       "      <th>bus_number</th>\n",
       "      <th>service_id</th>\n",
       "      <th>ride_check_date</th>\n",
       "      <th>pattern</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>apc_trip_id</th>\n",
       "      <th>apc_lat</th>\n",
       "      <th>apc_lon</th>\n",
       "      <th>stop_abbr</th>\n",
       "      <th>apc_stop_name</th>\n",
       "      <th>ride_check_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>661</td>\n",
       "      <td>2</td>\n",
       "      <td>35160</td>\n",
       "      <td>35806</td>\n",
       "      <td>35806</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1505</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>20190101</td>\n",
       "      <td>03</td>\n",
       "      <td>12381</td>\n",
       "      <td>178755</td>\n",
       "      <td>36153524</td>\n",
       "      <td>-86800747</td>\n",
       "      <td>CHU20AWN</td>\n",
       "      <td>CHURCH ST &amp; 20TH AVE N WB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "      <td>14</td>\n",
       "      <td>31233</td>\n",
       "      <td>53131</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1505</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>20190101</td>\n",
       "      <td>12</td>\n",
       "      <td>12397</td>\n",
       "      <td>178858</td>\n",
       "      <td>36059458</td>\n",
       "      <td>-86641035</td>\n",
       "      <td>BELHHINN</td>\n",
       "      <td>BELL RD &amp; HICKORY HIGHLANDS DR NB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2598</td>\n",
       "      <td>51</td>\n",
       "      <td>32701</td>\n",
       "      <td>61148</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1505</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>20190101</td>\n",
       "      <td>12</td>\n",
       "      <td>12397</td>\n",
       "      <td>178858</td>\n",
       "      <td>36140803</td>\n",
       "      <td>-86738128</td>\n",
       "      <td>MURTRAWN</td>\n",
       "      <td>MURFREESBORO PIKE &amp; TRANSIT AVE WB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5277</td>\n",
       "      <td>61</td>\n",
       "      <td>22797</td>\n",
       "      <td>28519</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1700</td>\n",
       "      <td>716</td>\n",
       "      <td>7</td>\n",
       "      <td>20190101</td>\n",
       "      <td>07</td>\n",
       "      <td>12399</td>\n",
       "      <td>178877</td>\n",
       "      <td>36153661</td>\n",
       "      <td>-86784135</td>\n",
       "      <td>11ALAUSF</td>\n",
       "      <td>11TH AVE &amp; LAUREL ST SB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4663</td>\n",
       "      <td>62</td>\n",
       "      <td>22826</td>\n",
       "      <td>30399</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1700</td>\n",
       "      <td>716</td>\n",
       "      <td>7</td>\n",
       "      <td>20190101</td>\n",
       "      <td>07</td>\n",
       "      <td>12399</td>\n",
       "      <td>178877</td>\n",
       "      <td>36152044</td>\n",
       "      <td>-86784228</td>\n",
       "      <td>11A12ASN</td>\n",
       "      <td>11TH AVE &amp; 12TH AVE NB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_load  apc_stop_id  stop_number e_time actual_arrival_time  \\\n",
       "0             2          661            2  35160               35806   \n",
       "1             0          411           14  31233               53131   \n",
       "2             0         2598           51  32701               61148   \n",
       "3             0         5277           61  22797               28519   \n",
       "4             0         4663           62  22826               30399   \n",
       "\n",
       "  actual_depart_time scheduled_arrival_time scheduled_departure_time  \\\n",
       "0              35806                     -1                       -1   \n",
       "1                 -1                     -1                       -1   \n",
       "2                 -1                     -1                       -1   \n",
       "3                 -1                     -1                       -1   \n",
       "4                 -1                     -1                       -1   \n",
       "\n",
       "   sequence  board_count  alight_count  line block_name  bus_number  \\\n",
       "0        11            0             2    10       1505         135   \n",
       "1         6            1             0    15       1505         135   \n",
       "2        43            1             0    15       1505         135   \n",
       "3         8            1             0    17       1700         716   \n",
       "4         9            1             0    17       1700         716   \n",
       "\n",
       "   service_id ride_check_date pattern  pattern_id  apc_trip_id   apc_lat  \\\n",
       "0           7        20190101      03       12381       178755  36153524   \n",
       "1           7        20190101      12       12397       178858  36059458   \n",
       "2           7        20190101      12       12397       178858  36140803   \n",
       "3           7        20190101      07       12399       178877  36153661   \n",
       "4           7        20190101      07       12399       178877  36152044   \n",
       "\n",
       "    apc_lon stop_abbr                       apc_stop_name  ride_check_mode  \n",
       "0 -86800747  CHU20AWN           CHURCH ST & 20TH AVE N WB                2  \n",
       "1 -86641035  BELHHINN   BELL RD & HICKORY HIGHLANDS DR NB                2  \n",
       "2 -86738128  MURTRAWN  MURFREESBORO PIKE & TRANSIT AVE WB                2  \n",
       "3 -86784135  11ALAUSF             11TH AVE & LAUREL ST SB                2  \n",
       "4 -86784228  11A12ASN              11TH AVE & 12TH AVE NB                2  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to datetime \n",
    "apc_df['ride_check_date'] = apc_df['ride_check_date'].apply(lambda x: datetime.datetime.strptime(x,'%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_times (time) :\n",
    "    \"\"\"\n",
    "    :param time: time in seconds past midnight \n",
    "    :return: time converted from seconds past midnight to HH:MM:SS\n",
    "    \"\"\"\n",
    "    time = int(time)\n",
    "    if time == -1 :\n",
    "        return None \n",
    "    else: \n",
    "        fixed_time = dt.timedelta(seconds = time) \n",
    "        return fixed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_time\n",
      "actual_arrival_time\n",
      "actual_depart_time\n",
      "scheduled_arrival_time\n",
      "scheduled_departure_time\n"
     ]
    }
   ],
   "source": [
    "#convert all times from seconds past midnight to HH:MM:SS\n",
    "for l in ['e_time','actual_arrival_time','actual_depart_time','scheduled_arrival_time','scheduled_departure_time']:\n",
    "    print(l)\n",
    "    apc_df[l]= apc_df.swifter.set_npartitions(20).apply(lambda x: fix_times(x[l]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3204725"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apc_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_df.to_parquet('data/apc_cleaned_jan_through_dec_2019.parquet', engine='fastparquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the joined trips stops file (run this once).\n",
    "This is saved as 'trips_gtfs_surrogate.parquet.gzip' in Teams under general > datasets > wego-occupancy > APCData > Trips and Stops sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=pd.read_excel('data/TripsFile.xlsx',sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.columns = ['route_id', 'version', 'trip_start_time', 'pattern_id','trip_id', 'direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['trip_start_time'] = pd.to_datetime(trips[\"trip_start_time\"], unit='s').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops=pd.read_excel('StopsFile.xlsx',sheet_name=\"update-pattern-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.columns = ['pattern_id', 'stop_id', 'lat', 'lon','stop_seq', 'direction','version','activation_date','deactivation_date','route_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stop_sequence = pd.merge(stops, trips,  how='left', on=['version','route_id','direction','pattern_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check no duplicates\n",
    "dups = trip_stop_sequence.loc[trip_stop_sequence.duplicated(subset = ['version','stop_id','trip_id','route_id' ,'pattern_id','stop_seq','activation_date'], keep=False)]\n",
    "dups.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stop_sequence.to_parquet('data/trips_gtfs_surrogate.parquet.gzip',engine='pyarrow',compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create version ID column of APC data.\n",
    "\n",
    "This is necessary to be able to merge the APC with the trip-stops information. The APC with version for 2019 and 2020 are saved in Teams under general > datasets > wego-occupancy > APCData > Cleaned APC 2019-2020 data. The 2019 data set with version is called apc_df_2019_jan_dec_with_version.parquet.gz and the 2020 data set with version is called apc_df_2020_jan_oct_with_version.parquet.gz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read joined trip-stops information file AND APC file\n",
    "trip_stop_sequence = pd.read_parquet('cleandata/trips_gtfs_surrogate.parquet.gzip',engine='pyarrow')\n",
    "#replace with 2020 apc\n",
    "apc_df=pd.read_parquet('cleandata/apc_cleaned_jan_through_dec_2019.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_date=trip_stop_sequence[['apc_trip_id', 'version', 'activation_date']].drop_duplicates(['apc_trip_id','version', 'activation_date'],keep='first')\n",
    "trip_date=trip_date[['apc_trip_id', 'version', 'activation_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shriyakaram/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "apc_df_trip_dates=apc_df[['apc_trip_id','ride_check_date']]\n",
    "apc_df_trip_dates=apc_df_trip_dates.drop_duplicates(['apc_trip_id','ride_check_date'],keep='first',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_df_trip_dates=apc_df_trip_dates.reset_index()\n",
    "trip_date=trip_date.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_version_id(apc_trip_id, ride_check_date) :\n",
    "    temp = trip_date.loc[(trip_date['apc_trip_id'] == apc_trip_id)]\n",
    "    if (temp is None or temp.size==0):\n",
    "        return 0\n",
    "    temp['ride_check_date'] = ride_check_date\n",
    "    temp['days'] = (temp['ride_check_date'] - temp['activation_date']).dt.days\n",
    "    df3 = temp.loc[temp['days'] >= 0]\n",
    "    if (df3 is None or df3.size==0):\n",
    "        return 0\n",
    "    df3=df3.reset_index()\n",
    "    df3 = df3.sort_values(['days'], ascending = True)    \n",
    "    return df3['version'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ae4b29749944c1a985813035dcabc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dask Apply', max=20.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "apc_df_trip_dates['version']= apc_df_trip_dates.swifter.set_npartitions(20).apply(lambda x: find_version_id(x['apc_trip_id'], x['ride_check_date'] ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>apc_trip_id</th>\n",
       "      <th>ride_check_date</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>193712</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>193713</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>193714</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>193716</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>193718</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  apc_trip_id ride_check_date  version\n",
       "0      0       193712      2020-01-01       58\n",
       "1      1       193713      2020-01-01       58\n",
       "2      2       193714      2020-01-01       58\n",
       "3      3       193716      2020-01-01       58\n",
       "4      4       193718      2020-01-01       58"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apc_df_trip_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_df_trip_dates = apc_df_trip_dates.loc[ : , ('apc_trip_id', 'ride_check_date', 'version')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_df = apc_df.merge(apc_df_trip_dates, on=['apc_trip_id', 'ride_check_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that there are no null version Ids (!!)\n",
    "apc_df_trip_dates.loc[(apc_df_trip_dates.version==0)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_df=pd.read_parquet('cleandata/apc_df_2019_jan_dec_with_version.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1735230"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apc_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge APC with version WITH full trips-stops information\n",
    "\n",
    "The WeGo APC data contains data of non-zero boardings and alightings. We want to create a full data set that includes both non-zero and zero boardings and alightings. This is done by augmenting the APC data with the joined trips-stops information.\n",
    "\n",
    "These merged files for 2019-2020 are saved in Teams under general > datasets > wego-occupancy > APCData > Merged APC 2019-2020 data. They are saved in csv files for every 2 months.\n",
    "\n",
    "For 2020, only run for months Jan through August."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_df=pd.read_parquet('cleandata/apc_df_2019_jan_dec_with_version.parquet', engine='fastparquet')\n",
    "trip_stop_sequence = pd.read_parquet('cleandata/trips_gtfs_surrogate.parquet.gzip',engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running month by month:\n",
    "jan = apc_df[apc_df['ride_check_date'].dt.month == 1]\n",
    "#feb = apc_df[apc_df['ride_check_date'].dt.month == 2]\n",
    "#mar = apc_df[apc_df['ride_check_date'].dt.month == 3]\n",
    "#apr = apc_df[apc_df['ride_check_date'].dt.month == 4]\n",
    "#may = apc_df[apc_df['ride_check_date'].dt.month == 5]\n",
    "#jun = apc_df[apc_df['ride_check_date'].dt.month == 6]\n",
    "#jul = apc_df[apc_df['ride_check_date'].dt.month == 7]\n",
    "#aug = apc_df[apc_df['ride_check_date'].dt.month == 8]\n",
    "#sep = apc_df[apc_df['ride_check_date'].dt.month == 9]\n",
    "#octo = apc_df[apc_df['ride_check_date'].dt.month == 10]\n",
    "#nov = apc_df[apc_df['ride_check_date'].dt.month == 11]\n",
    "#dec = apc_df[apc_df['ride_check_date'].dt.month == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan = jan.sort_values(['ride_check_date', 'apc_trip_id', 'sequence'], ascending= True)\n",
    "jan['ride_check_date'] = jan['ride_check_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the renaming of the trips_stop_sequence file. \n",
    "trip_stop_sequence.columns = ['pattern_id', 'stop_abbr', 'lat', 'lon', 'sequence', 'direction',\n",
    "                 'version', 'activation_date', 'deactivation_date', 'line', 'trip_start_time',\n",
    "                 'apc_trip_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix lat and lon values\n",
    "trip_stop_sequence['lat']=trip_stop_sequence.lat/1e7\n",
    "trip_stop_sequence['lon']=trip_stop_sequence.lon/1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsdata=trip_stop_sequence[['apc_trip_id','trip_start_time','pattern_id','version','line','stop_abbr','lat','lon','sequence','direction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_values(df):\n",
    "    \"\"\"\n",
    "    fill nan values in the dataframe that result from the left join\n",
    "    \n",
    "    :param df: the pandas DataFrame after APC and trips/stops data have been combined\n",
    "    \"\"\"\n",
    "    filled = df.copy()\n",
    "\n",
    "    # missing board and alight counts are all 0\n",
    "    filled[['board_count', 'alight_count']] = filled[['board_count', 'alight_count']].fillna(0)\n",
    "\n",
    "    # otherwise, fill in missing information from existing apc rows\n",
    "    filled[['initial_load', 'line', 'block_name', 'bus_number',\n",
    "            'service_id', 'ride_check_date', 'pattern', 'apc_trip_id']] = filled[\n",
    "        ['initial_load', 'line', 'block_name', 'bus_number',\n",
    "         'service_id', 'ride_check_date', 'pattern', 'apc_trip_id']].fillna(method='ffill', axis=0).fillna(method='bfill',\n",
    "                                                                                                         axis=0)\n",
    "    return filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bus_occupancy(df):\n",
    "    \"\"\"\n",
    "    calculate occupancy at each stop along a route\n",
    "\n",
    "    :param df: dataframe with board/alight values for all stops along a single trip\n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "\n",
    "    tmp['initial_load'] = pd.to_numeric(tmp['initial_load'], errors='coerce')\n",
    "    tmp['board_count'] = pd.to_numeric(tmp['board_count'], errors='coerce')\n",
    "    tmp['alight_count'] = pd.to_numeric(tmp['alight_count'], errors='coerce')\n",
    "\n",
    "    # calc occupancy net change\n",
    "    tmp['occupancy_net_change'] = tmp['board_count'] - tmp['alight_count']\n",
    "\n",
    "    # calc cumulative sum in occupancy net change as an intermediate step\n",
    "    tmp_sum_df = pd.DataFrame(tmp['occupancy_net_change'].cumsum())\n",
    "    tmp_sum_df.columns = ['tmp_sum']\n",
    "\n",
    "    # merge tmp sum (cumulative sum) into tmp\n",
    "    tmp = tmp.merge(tmp_sum_df, left_index=True, right_index=True)\n",
    "\n",
    "    # calc occupancy for a particular stop\n",
    "    tmp['occupancy'] = tmp['tmp_sum'] + tmp['initial_load']\n",
    "\n",
    "    return tmp.drop(columns=['tmp_sum', 'occupancy_net_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stops_merge_for_trip (group) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Merge APC group with trips/stops information, and calculate occupancy \n",
    "\n",
    "    :param: group of APC dataframe based on apc_trip_id, pattern_id, line, ride_check_date, version\n",
    "    \"\"\"\n",
    "    \n",
    "    apc_stops = group.reset_index()\n",
    "    trip = apc_stops.apc_trip_id[0]\n",
    "    date = apc_stops.ride_check_date[0]\n",
    "    version = apc_stops.version[0]\n",
    "    line = apc_stops.line[0]\n",
    "    \n",
    "    #get expected stops from joined file\n",
    "    all_stops = tripsdata[(tripsdata.apc_trip_id == trip) & (tripsdata.version == version) & (tripsdata.line == line)]\n",
    "    all_stops['ride_check_date'] = date\n",
    "    all_stops.sort_values(by=['sequence'])\n",
    "\n",
    "    #left join with trips on the left, apc on the right \n",
    "    merge = pd.merge(all_stops, apc_stops, how='left', on=['apc_trip_id', 'ride_check_date', 'sequence', 'stop_abbr',\n",
    "                                                           'version', 'line']).sort_values(by=['sequence']).reset_index(drop=True)\n",
    "\n",
    "    #fill NaN values and calculate occupancy \n",
    "    filled = fill_nan_values(merge)\n",
    "    occupancy_df = calc_bus_occupancy(filled)\n",
    "    \n",
    "    #drop apc columns \n",
    "    occupancy_df = occupancy_df.drop(columns=['apc_stop_id', 'stop_number','block_name','apc_stop_name','apc_lat','pattern_id_y','apc_lon', 'index'])\n",
    "\n",
    "    #rename trips table pattern ID\n",
    "    occupancy_df = occupancy_df.rename(columns={'pattern_id_x' : 'pattern_id'})\n",
    "\n",
    "    return occupancy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_parallel(df_grouped, stops_merge_for_trip):\n",
    "    with Pool(cpu_count()) as p:\n",
    "        ret_list=p.map(stops_merge_for_trip, [group for name, group in df_grouped])\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return pd.concat(ret_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    #change file name here\n",
    "    df_grouped = jan.groupby(['apc_trip_id', 'pattern_id','line','ride_check_date', 'version'])\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    parallel_result = apply_parallel(df_grouped, stops_merge_for_trip)\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"time elapsed:\", end - start)\n",
    "\n",
    "    #rename saved file\n",
    "    parallel_result.to_csv('jan19_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append all month data frames and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the steps are just show from Jul - Dec 2019.\n",
    "jul = pd.read_csv('jul19_merged.csv', index_col=0)\n",
    "aug = pd.read_csv('aug19_merged.csv', index_col=0)\n",
    "sep = pd.read_csv('sep19_merged.csv', index_col=0)\n",
    "octo = pd.read_csv('oct19_merged.csv', index_col=0)\n",
    "nov = pd.read_csv('nov19_merged.csv', index_col=0)\n",
    "dec = pd.read_csv('dec19_merged.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jul = jul.reset_index()\n",
    "jul = jul.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = aug.reset_index()\n",
    "aug = aug.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = sep.reset_index()\n",
    "sep = sep.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octo = octo.reset_index()\n",
    "octo = octo.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nov = nov.reset_index()\n",
    "nov = nov.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = dec.reset_index()\n",
    "dec = dec.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append data\n",
    "jul_aug = jul.append(aug)\n",
    "jul_aug = jul_aug.reset_index(drop=True)\n",
    "\n",
    "sep_oct = sep.append(octo)\n",
    "sep_oct = sep_oct.reset_index(drop=True)\n",
    "\n",
    "nov_dec = nov.append(dec)\n",
    "nov_dec = nov_dec.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jul_aug.to_csv('wego_jul_aug_2019_merged_apc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_oct.to_csv('wego_sep_oct_2019_merged_apc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nov_dec.to_csv('wego_nov_dec_2019_merged_apc.csv')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
